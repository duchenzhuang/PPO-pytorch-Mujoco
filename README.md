# PPO-pytorch-Mujoco
Implement PPO algorithm in mujoco environmentï¼Œsuch as Ant-v2, Humanoid-v2, Hopper-v2, Halfcheeth-v2.

## Requirements
- python 3.7.6
- gym 0.17.6
- mujoco_py 2.0.2.10
- pytorch

## Playing Example
```
$ python main.py --env_name Hopper-v2
```
